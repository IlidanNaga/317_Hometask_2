{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from scipy import sparse\n",
    "from math import exp\n",
    "\n",
    "from oracles import BinaryLogistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDClassifier:\n",
    "    \"\"\"\n",
    "    Реализация метода градиентного спуска для произвольного\n",
    "    оракула, соответствующего спецификации оракулов из модуля oracles.py\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, loss_function, step_alpha=1, step_beta=0, \n",
    "                 tolerance=1e-5, max_iter=1000, **kwargs):\n",
    "        \"\"\"\n",
    "        loss_function - строка, отвечающая за функцию потерь классификатора. \n",
    "        Может принимать значения:\n",
    "        - 'binary_logistic' - бинарная логистическая регрессия\n",
    "                |\n",
    "        step_alpha - float, параметр выбора шага из текста задания\n",
    "        \n",
    "        step_beta- float, параметр выбора шага из текста задания\n",
    "        \n",
    "        tolerance - точность, по достижении которой, необходимо прекратить оптимизацию.\n",
    "        Необходимо использовать критерий выхода по модулю разности соседних значений функции:\n",
    "        если |f(x_{k+1}) - f(x_{k})| < tolerance: то выход \n",
    "        \n",
    "        max_iter - максимальное число итераций     \n",
    "        \n",
    "        **kwargs - аргументы, необходимые для инициализации   \n",
    "        \"\"\"\n",
    "\n",
    "        if loss_function != 'binary_logistic':\n",
    "            raise TypeError\n",
    "\n",
    "        self.loss = loss_function\n",
    "\n",
    "        self.step_alpha = step_alpha\n",
    "        self.step_beta = step_beta\n",
    "\n",
    "        self.tolerance = tolerance\n",
    "\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "        self.oracle = BinaryLogistic(l2_coef=kwargs['l2_coef'])\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y, w_0=None, trace=False):\n",
    "        \"\"\"\n",
    "        Обучение метода по выборке X с ответами y\n",
    "        \n",
    "        X - scipy.sparse.csr_matrix или двумерный numpy.array\n",
    "        \n",
    "        y - одномерный numpy array\n",
    "        \n",
    "        w_0 - начальное приближение в методе\n",
    "        \n",
    "        trace - переменная типа bool\n",
    "      \n",
    "        Если trace = True, то метод должен вернуть словарь history, содержащий информацию \n",
    "        о поведении метода. Длина словаря history = количество итераций + 1 (начальное приближение)\n",
    "\n",
    "        history['time']: list of floats, содержит интервалы времени между двумя итерациями метода\n",
    "        history['func']: list of floats, содержит значения функции на каждой итерации\n",
    "        (0 для самой первой точки)\n",
    "        \"\"\"\n",
    "        \n",
    "        def lambda_k(k):\n",
    "            return self.step_alpha / (k ** self.step_beta)\n",
    "\n",
    "        \n",
    "        if w_0 is None:\n",
    "            w = np.zeros(X.shape[1])\n",
    "        \n",
    "        history = {}\n",
    "        times = []\n",
    "        funcs = []\n",
    "        \n",
    "        cur_func = self.oracle.func(X, y, w)\n",
    "        funcs.append(cur_func)\n",
    "        times.append(0)\n",
    "        \n",
    "        i = 1\n",
    "        while i <= self.max_iter:\n",
    "            \n",
    "            time_b4 = time()\n",
    "            \n",
    "            w_next = w - lambda_k(i) * self.oracle.grad(X, y, w)\n",
    "            \n",
    "            time_delta = time() - time_b4\n",
    "            \n",
    "            times.append(time_delta)\n",
    "            \n",
    "            next_func = self.oracle.func(X, y, w_next)\n",
    "            funcs.append(next_func)\n",
    "            \n",
    "            if abs(next_func - cur_func) < self.tolerance:\n",
    "                break\n",
    "                \n",
    "            w = w_next\n",
    "            cur_func = next_func\n",
    "            i += 1\n",
    "            \n",
    "        history['time'] = times\n",
    "        history['func'] = funcs\n",
    "        \n",
    "        self.w = w_next\n",
    "        \n",
    "        if trace:\n",
    "            return history\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Получение меток ответов на выборке X\n",
    "        \n",
    "        X - scipy.sparse.csr_matrix или двумерный numpy.array\n",
    "        \n",
    "        return: одномерный numpy array с предсказаниями\n",
    "        \"\"\"\n",
    "        \n",
    "        ans = np.zeros(X.shape[0]).astype(int)\n",
    "        \n",
    "        for enum, item in enumerate(X):\n",
    "            mul = np.sum(self.w * item)\n",
    "            proba = 1 / (1 + exp(-1 * mul))\n",
    "            \n",
    "            if proba < 0.5:\n",
    "                ans[enum] = -1\n",
    "            else:\n",
    "                ans[enum] = 1\n",
    "                \n",
    "        return ans\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Получение вероятностей принадлежности X к классу k\n",
    "        \n",
    "        X - scipy.sparse.csr_matrix или двумерный numpy.array\n",
    "        \n",
    "        return: двумерной numpy array, [i, k] значение соответветствует вероятности\n",
    "        принадлежности i-го объекта к классу k \n",
    "        \"\"\"\n",
    "        ans = []\n",
    "        for enum, item in enumerate(X):\n",
    "            mul = np.sum(self.w * item)\n",
    "            proba = 1 / (1 + exp(-1 * mul))\n",
    "            \n",
    "            ans.append([proba, 1 - proba])\n",
    "                \n",
    "        return np.array(ans)\n",
    "        \n",
    "    def get_objective(self, X, y):\n",
    "        \"\"\"\n",
    "        Получение значения целевой функции на выборке X с ответами y\n",
    "        \n",
    "        X - scipy.sparse.csr_matrix или двумерный numpy.array\n",
    "        y - одномерный numpy array\n",
    "        \n",
    "        return: float\n",
    "        \"\"\"\n",
    "        return self.oracle.func(X, y, self.w)\n",
    "        \n",
    "    def get_gradient(self, X, y):\n",
    "        \"\"\"\n",
    "        Получение значения градиента функции на выборке X с ответами y\n",
    "        \n",
    "        X - scipy.sparse.csr_matrix или двумерный numpy.array\n",
    "        y - одномерный numpy array\n",
    "        \n",
    "        return: numpy array, размерность зависит от задачи\n",
    "        \"\"\"\n",
    "        return self.oracle.grad(X, y, self.w)\n",
    "    \n",
    "    def get_weights(self):\n",
    "        \"\"\"\n",
    "        Получение значения весов функционала\n",
    "        \"\"\"    \n",
    "        return self.w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (np.random.rand(10)).reshape(2, 5)\n",
    "y = np.array([1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GDClassifier('binary_logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5)\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39024708 0.59416511 0.64308653 0.26849751 0.39084895]\n",
      "[0.80672398 0.41287117 0.44277221 0.62547913 0.76510014]\n"
     ]
    }
   ],
   "source": [
    "for item in X:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = X.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39024708, 0.59416511, 0.64308653, 0.26849751, 0.39084895],\n",
       "       [0.80672398, 0.41287117, 0.44277221, 0.62547913, 0.76510014]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
